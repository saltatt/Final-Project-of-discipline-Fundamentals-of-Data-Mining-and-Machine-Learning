# Проект: Классификация видеоигр

## Авторы
- Тұрғын Салтанат  
- Уршукова Томирис

## Описание проекта
В рамках финального проекта проведён анализ датасета видеоигр с использованием **линейной и логистической регрессии с нуля**, а также **Decision Tree**.  
Проект демонстрирует:

- Реализацию градиентного спуска для линейной и логистической регрессии  
- Использование mini-batch градиентного спуска  
- Визуализацию данных (scatter plot, регрессионная линия, доверительный интервал)  
- Сравнение моделей по метрикам: Accuracy, Precision, Recall, F1-score, Confusion Matrix, ROC AUC  
- Эксперименты с различными learning rate, epoch и batch size  
- Интерактивный интерфейс с виджетами для выбора модели и параметров обучения  

## Датасет
Данные взяты с Kaggle: [IMDb Video Games Dataset](https://www.kaggle.com/datasets/lorentzyeung/imdb-video-games-dataset)  
Количество строк: 14682. Основные используемые колонки:

- **User Rating** — независимая переменная (X)  
- **Popularity** — зависимая переменная (y)  

## Структура проекта
- `Final Project.ipynb` — Jupyter Notebook с реализацией моделей, графиками и интерфейсом  
- `README.md` — описание проекта и инструкция по запуску  
- `requirements.txt` — список зависимостей Python  

## Запуск проекта в Google Colab
1. Перейдите по ссылке на Notebook в Colab:  
   [Final Project.ipynb](https://colab.research.google.com/drive/1AasfEoZ9XuyUe95TFJgGBxnr40dwAqD_)
2. Установите зависимости (если нужно):

```python
!pip install numpy pandas matplotlib seaborn scikit-learn ipywidgets scipy
```
3. Используйте интерактивные виджеты для выбора модели и параметров обучения.

## Использование моделей

* **Линейная регрессия** — предсказывает численную популярность игры по рейтингу пользователей
* **Логистическая регрессия (с нуля)** — бинарная классификация: высокая или низкая популярность
* **Decision Tree** — дополнительная модель для сравнения точности

## Метрики оценки

Для каждой модели вычисляются:

* Accuracy
* Precision
* Recall
* F1-score
* Confusion matrix
* ROC AUC (для бинарной классификации)

## Эксперименты

* Влияние **learning rate** на сходимость
* Влияние **количества эпох**
* Использование **mini-batch градиентного спуска** с разными batch size
* Сравнение моделей по качеству и объяснение различий

## Примечания

* Для линейной и логистической регрессии градиенты реализованы вручную с использованием `numpy`
* Для Decision Tree используется `sklearn`
* Все графики и визуализации встроены в Notebook


# **2️⃣ requirements.txt**

```
numpy
pandas
matplotlib
seaborn
scikit-learn
ipywidgets
scipy
```



